{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieLens_TensorFlow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNt7ljBRfnEc"
      },
      "source": [
        "# Neural Collaborative Filtering Demo Notebook\n",
        "This demo notebook is intended to show our code/model definitions and as as a sanity check. It uses a small dataset and has not been tuned for performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZeSXsXodObp"
      },
      "source": [
        "## Training Section\n",
        "## Select model type here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qxVU_vmdPPI"
      },
      "source": [
        "# Options are: \"GMF\", \"MLP\", \"NeuMF\", \"Outer\", \"ResNet\"\n",
        "model_type = \"GMF\""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6D1ud0HVRoj"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH4afYylVRoj"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "import heapq\n",
        "import math"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOrz3-zQVRoj"
      },
      "source": [
        "## Data Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm0uKl4NVRok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0ac633-251d-4ce7-d398-50bfdbfa1230"
      },
      "source": [
        "np.random.seed(0)\n",
        "ratings_dir = './Data/ml-100k/u.data'\n",
        "\n",
        "# Read in ratings data\n",
        "ratings = pd.read_csv(ratings_dir, sep='\\t')\n",
        "ratings = ratings.sort_values(by=['userId', 'movieId'])\n",
        "print(ratings)\n",
        "\n",
        "num_users = len(ratings['userId'].unique())\n",
        "num_items = len(ratings['movieId'].unique())\n",
        "\n",
        "print('Num Users:', num_users)\n",
        "print('Num Movies:', num_items)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       userId  movieId  rating  timestamp\n",
            "32236       1        1       5  874965758\n",
            "23171       1        2       3  876893171\n",
            "83307       1        3       4  878542960\n",
            "62631       1        4       3  876893119\n",
            "47638       1        5       3  889751712\n",
            "...       ...      ...     ...        ...\n",
            "68857     943     1067       2  875501756\n",
            "74200     943     1074       4  888640250\n",
            "78704     943     1188       3  888640250\n",
            "86600     943     1228       3  888640275\n",
            "92115     943     1330       3  888692465\n",
            "\n",
            "[100000 rows x 4 columns]\n",
            "Num Users: 943\n",
            "Num Movies: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEEtXx7RVVvg",
        "outputId": "5b3794dc-4bb7-40a3-939f-25f4e73fbf65"
      },
      "source": [
        "# Find the latest rating each user has made\n",
        "ratings['latest'] = ratings.groupby(['userId'])['timestamp'].rank(method='first', ascending=False)\n",
        "\n",
        "# Separate the latest rating into the test dataset\n",
        "# Keep all other ratings in the train dataset\n",
        "train_ratings = ratings[ratings['latest'] != 1]\n",
        "test_ratings = ratings[ratings['latest'] == 1]\n",
        "\n",
        "# Remove timestamp field\n",
        "train_ratings = train_ratings[['userId', 'movieId', 'rating']]\n",
        "test_ratings = test_ratings[['userId', 'movieId', 'rating']]\n",
        "\n",
        "print('Columns:', train_ratings.columns.values)\n",
        "print('Interactions in Training Set:', train_ratings.shape[0])\n",
        "print('Interactions in Testing Set:', test_ratings.shape[0])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Columns: ['userId' 'movieId' 'rating']\n",
            "Interactions in Training Set: 99057\n",
            "Interactions in Testing Set: 943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml1qDojt3Lcb"
      },
      "source": [
        "### Convert to Implicit Feedback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BghlYpWWZsc",
        "outputId": "6c5b1e62-e80d-48f8-c3bc-33149f05fed6"
      },
      "source": [
        "# Convert rating to 1 for everything to mark that the user has watched this item\n",
        "train_ratings.loc[:, 'rating'] = 1\n",
        "print(train_ratings)\n",
        "\n",
        "# Convert Test Rating dataframe into list\n",
        "test_ratings_list = []\n",
        "for user, item in zip(test_ratings['userId'], test_ratings['movieId']):\n",
        "  test_ratings_list.append([user, item])\n",
        "\n",
        "test_ratings = test_ratings_list\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       userId  movieId  rating\n",
            "32236       1        1       1\n",
            "23171       1        2       1\n",
            "83307       1        3       1\n",
            "62631       1        4       1\n",
            "47638       1        5       1\n",
            "...       ...      ...     ...\n",
            "68857     943     1067       1\n",
            "74200     943     1074       1\n",
            "78704     943     1188       1\n",
            "86600     943     1228       1\n",
            "92115     943     1330       1\n",
            "\n",
            "[99057 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8ObmXC23Pc2"
      },
      "source": [
        "# Define model to generate negative samples for each training epoch\n",
        "def get_train_instances(ratings, num_negatives):\n",
        "    # Add negative samples with rating = 0\n",
        "    all_movies = ratings['movieId'].unique()\n",
        "\n",
        "    users, items, labels = [], [], []\n",
        "    user_item_set = set(zip(train_ratings['userId'], train_ratings['userId']))\n",
        "    num_negatives = 4\n",
        "\n",
        "    for (u, i) in user_item_set:\n",
        "        users.append(u)\n",
        "        items.append(i)\n",
        "        labels.append(1)\n",
        "        for _ in range(num_negatives):\n",
        "            negative_item = np.random.choice(all_movies)\n",
        "            while (u, negative_item) in user_item_set:\n",
        "                negative_item = np.random.choice(all_movies)\n",
        "            users.append(u)\n",
        "            items.append(negative_item)\n",
        "            labels.append(0)\n",
        "    \n",
        "    return users, items, labels"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qChNhqptxKA-",
        "outputId": "55eb833b-a8b4-43e9-a094-2b49c0f0727d"
      },
      "source": [
        "# Generate 100 Negative Test Examples\n",
        "# Add negative samples\n",
        "all_movies = ratings['movieId'].unique()\n",
        "\n",
        "users, items, labels = [], [], []\n",
        "user_item_set = set(zip(train_ratings['userId'], train_ratings['movieId']))\n",
        "user_set = set(train_ratings['userId'])\n",
        "num_test_negatives = 99\n",
        "test_negatives = []\n",
        "\n",
        "for u in user_set:\n",
        "  negatives = []\n",
        "\n",
        "  for _ in range(num_test_negatives):\n",
        "    negative_item = np.random.choice(all_movies)\n",
        "    while (u, negative_item) in user_item_set:\n",
        "      negative_item = np.random.choice(all_movies)\n",
        "    \n",
        "    negatives.append(negative_item)\n",
        "  \n",
        "  test_negatives.append(negatives)\n",
        "\n",
        "print('Number of users:', len(test_negatives))\n",
        "print('Number of negative points:', len(test_negatives[138]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of negative points: 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZo-UkaRso69"
      },
      "source": [
        "## Define Models\n",
        "\n",
        "Each model starts with the same inputs and embeddings. The GMF passes the embedding vectors straight into element-wise multiplication. The MLF concatenates the vectors and passes them through an MLP. The NeuMF ensembles the MLP and GMF models. The Outer Product takes the outer product of the two vectors and passes the resulting 2D matrix through a CNN. Finally, the ResNet also takes the outer product of the two vectors and passes the resulting 2D matrix through a ResNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dERxM2CB80nF"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Input, Dense, Reshape, Multiply, Flatten, Layer, Lambda, Concatenate, Conv2D, MaxPool2D\n",
        "from keras import initializers, regularizers\n",
        "from keras.regularizers import l2\n",
        "import sys\n",
        "\n",
        "def get_GMFmodel(num_users, num_items, latent_dim):\n",
        "  user_input = Input(shape = (1,), dtype = 'int32', name = 'user')\n",
        "  item_input = Input(shape = (1,), dtype = 'int32', name = 'item')\n",
        "\n",
        "  user_embedding = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embed',\n",
        "                             embeddings_initializer = initializers.RandomNormal(stddev = 0.01), \n",
        "                             embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "  item_embedding = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embed',\n",
        "                             embeddings_initializer = initializers.RandomNormal(stddev = 0.01), \n",
        "                             embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "\n",
        "  user_latent = Flatten()(user_embedding(user_input))\n",
        "  item_latent = Flatten()(item_embedding(item_input))\n",
        "\n",
        "  prediction_vec = Multiply()([user_latent, item_latent])\n",
        "\n",
        "  prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(prediction_vec)\n",
        "\n",
        "  return Model(inputs=[user_input, item_input], outputs=prediction)\n",
        "\n",
        "\n",
        "def get_MLPmodel(num_users, num_items, latent_dim):\n",
        "  user_input = Input(shape = (1,), dtype = 'int32', name = 'user')\n",
        "  item_input = Input(shape = (1,), dtype = 'int32', name = 'item')\n",
        "  user_embedding = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embed', embeddings_initializer = initializers.RandomNormal(stddev = 0.01), embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "  item_embedding = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embed',embeddings_initializer = initializers.RandomNormal(stddev = 0.01), embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "  user_latent = Flatten()(user_embedding(user_input))\n",
        "  item_latent = Flatten()(item_embedding(item_input))\n",
        "  inputs = Concatenate()([user_latent, item_latent])\n",
        "  layer = Dense(64,activation='relu', name='Layer1', kernel_initializer='glorot_uniform', kernel_regularizer=l2())(inputs)\n",
        "  layer = Dense(32, activation='relu', name='Layer3')(layer)\n",
        "  layer = Dense(16, activation='relu')(layer)\n",
        "  output = Dense(1, activation='sigmoid', name='Layer4')(layer)\n",
        "  return Model(inputs=[user_input, item_input], outputs=output)\n",
        "\n",
        "\n",
        "def get_NeuMFmodel(num_users, num_items, latent_dim):\n",
        "  user_input = Input(shape = (1,), dtype = 'int32', name = 'user')\n",
        "  movie_input = Input(shape = (1,), dtype = 'int32', name = 'item')\n",
        "  user_embedding = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embed', embeddings_initializer = initializers.RandomNormal(stddev = 0.01), embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "  movie_embedding = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embed',embeddings_initializer = initializers.RandomNormal(stddev = 0.01), embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "  user_latent = Flatten()(user_embedding(user_input))\n",
        "  item_latent = Flatten()(movie_embedding(movie_input))\n",
        "  prediction_vec = Multiply()([user_latent, item_latent])\n",
        "  prediction_GMF = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(prediction_vec)\n",
        "  inputs = Concatenate()([user_latent, item_latent])\n",
        "  layer = Dense(64,activation='relu', name='Layer1', kernel_initializer='glorot_uniform', kernel_regularizer=l2())(inputs)\n",
        "  layer = Dense(32, activation='relu', name='Layer3', kernel_regularizer=l2())(layer)\n",
        "  layer = Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0))(layer)\n",
        "  prediction_MLP = Dense(1, activation='sigmoid', name='Layer4')(layer)\n",
        "  predictions = Combine()([prediction_GMF, prediction_MLP])\n",
        "  return Model(inputs=[user_input, movie_input], outputs=predictions)\n",
        "\n",
        "class Combine(Layer):\n",
        "  def __init__(self):\n",
        "        super(Combine, self).__init__()\n",
        "        random_alpha = tf.random.uniform(shape=[1])\n",
        "        self.alpha = tf.Variable(initial_value=random_alpha, trainable=True)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return (1 - self.alpha)*inputs[0] + self.alpha*inputs[1]\n",
        "\n",
        "\n",
        "def get_OuterProductmodel(num_users, num_items, latent_dim):\n",
        "    user_input = Input(shape = (1,), dtype = 'int32', name = 'user')\n",
        "    item_input = Input(shape = (1,), dtype = 'int32', name = 'item')\n",
        "\n",
        "    user_embedding = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embed',\n",
        "                             embeddings_initializer = initializers.RandomNormal(stddev = 0.01), \n",
        "                             embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "    item_embedding = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embed',\n",
        "                             embeddings_initializer = initializers.RandomNormal(stddev = 0.01), \n",
        "                             embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "\n",
        "    user_latent = Flatten()(user_embedding(user_input))\n",
        "    item_latent = Flatten()(item_embedding(item_input))\n",
        "\n",
        "    latent_map = tf.linalg.matmul(tf.expand_dims(user_latent, -1), tf.expand_dims(item_latent, 1))\n",
        "\n",
        "    x = tf.expand_dims(latent_map, -1)\n",
        "\n",
        "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "    x = MaxPool2D(pool_size=2)(x)\n",
        "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "    x = MaxPool2D(pool_size=2)(x)\n",
        "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "    x = MaxPool2D(pool_size=2)(x)\n",
        "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(x)\n",
        "\n",
        "    return Model(inputs=[user_input, item_input], outputs=prediction)\n",
        "\n",
        "\n",
        "# https://towardsdatascience.com/building-a-resnet-in-keras-e8f1322a49ba\n",
        "def relu_bn(inputs):\n",
        "    relu = tf.keras.layers.ReLU()(inputs)\n",
        "    bn = tf.keras.layers.BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def residual_block(x, downsample = False, filters = 16, kernel_size = 3):\n",
        "    y = tf.keras.layers.Conv2D(kernel_size=kernel_size,\n",
        "               strides= (1 if not downsample else 2),\n",
        "               filters=filters,\n",
        "               padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = tf.keras.layers.Conv2D(kernel_size=kernel_size,\n",
        "               strides=1,\n",
        "               filters=filters,\n",
        "               padding=\"same\")(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = tf.keras.layers.Conv2D(kernel_size=1,\n",
        "                   strides=2,\n",
        "                   filters=filters,\n",
        "                   padding=\"same\")(x)\n",
        "    out = tf.keras.layers.Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def get_ResidualModel(num_users, num_items, embedding_dim, num_filters):\n",
        "    user_input = Input(shape = (1,), dtype = 'int32', name = 'user')\n",
        "    item_input = Input(shape = (1,), dtype = 'int32', name = 'item')\n",
        "\n",
        "    user_embedding = Embedding(input_dim = num_users, output_dim = embedding_dim, name = 'user_embed',\n",
        "                             embeddings_initializer = initializers.RandomNormal(stddev = 0.01), \n",
        "                             embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "    item_embedding = Embedding(input_dim = num_items, output_dim = embedding_dim, name = 'item_embed',\n",
        "                             embeddings_initializer = initializers.RandomNormal(stddev = 0.01), \n",
        "                             embeddings_regularizer = regularizers.l2(0), input_length = 1)\n",
        "\n",
        "    user_latent = Flatten()(user_embedding(user_input))\n",
        "    item_latent = Flatten()(item_embedding(item_input))\n",
        "\n",
        "    latent_map = tf.linalg.matmul(tf.expand_dims(user_latent, -1), tf.expand_dims(item_latent, 1))\n",
        "\n",
        "    x = tf.expand_dims(latent_map, -1)\n",
        "    \n",
        "    layers = [2, 2, 2]\n",
        "    \n",
        "    for i, num_layers in enumerate(layers):\n",
        "        for _ in range(num_layers):\n",
        "            x = residual_block(x, downsample = False, filters = num_filters, kernel_size = 3)\n",
        "          \n",
        "        if i == len(layers) - 1:\n",
        "            x = residual_block(x, downsample = False, filters = num_filters, kernel_size = 3)\n",
        "        else:\n",
        "            x = residual_block(x, downsample = True, filters = num_filters, kernel_size = 3)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(x)\n",
        "    \n",
        "    return Model(inputs=[user_input, item_input], outputs=prediction)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3XmZV-rstxi",
        "outputId": "52aee62c-77f3-4d0d-e5da-4e07b7e2de4f"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "topK = 10\n",
        "\n",
        "if model_type == \"GMF\":\n",
        "  model = get_GMFmodel(num_users + 1, num_items + 1, 8)\n",
        "  model.compile(optimizer=Adam(0.01), loss='binary_crossentropy')\n",
        "elif model_type == \"MLP\":\n",
        "  model = get_MLPmodel(num_users + 1, num_items + 1, 8)\n",
        "  model.compile(optimizer=Adam(0.01), loss='binary_crossentropy')\n",
        "elif model_type == \"NeuMF\":\n",
        "  model = get_NEUMFmodel(num_users + 1, num_items + 1, 8)\n",
        "  model.compile(optimizer=Adam(0.01), loss='binary_crossentropy')\n",
        "elif model_type == \"Outer\":\n",
        "  model = get_OuterProductmodel(num_users + 1, num_items + 1, 8)\n",
        "  model.compile(optimizer=Adam(0.01), loss='binary_crossentropy')\n",
        "elif model_type == \"ResNet\":\n",
        "  model = get_ResidualModel(num_users + 1, num_items + 1, 8, 32)\n",
        "  model.compile(optimizer=Adam(0.001), loss='binary_crossentropy')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user (InputLayer)               [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item (InputLayer)               [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "user_embed (Embedding)          (None, 1, 8)         7552        user[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "item_embed (Embedding)          (None, 1, 8)         13464       item[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 8)            0           user_embed[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 8)            0           item_embed[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 8)            0           flatten_9[0][0]                  \n",
            "                                                                 flatten_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 1)            9           multiply_2[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 21,025\n",
            "Trainable params: 21,025\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFgFhGmql_qx"
      },
      "source": [
        "### Define Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oxJIbrusvLw"
      },
      "source": [
        "def evaluateNDCG(ranked_list, target_item):\n",
        "    for i in range(len(ranked_list)):\n",
        "        if ranked_list[i] == target_item:\n",
        "            return math.log(2) / math.log(i + 2)\n",
        "  \n",
        "    return 0\n",
        "\n",
        "def hitRate(ranked_list, target_item):\n",
        "    for rank in ranked_list:\n",
        "        if target_item == rank:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "# This method calculates all the evaluation metrics. Individual methods are called from here.\n",
        "def evaluate(model, testPosRatings, testNegRatings, N):\n",
        "    hits = []\n",
        "    ndcgs = []\n",
        "    for i in range(len(testPosRatings)):\n",
        "        hit, ncdg = evaluate_one(model, testPosRatings[i], testNegRatings[i], N)\n",
        "        hits.append(hit)\n",
        "        ndcgs.append(ncdg)\n",
        "        \n",
        "    return np.array(hits).mean(), np.array(ndcgs).mean()\n",
        "\n",
        "def evaluate_one(model, posRating, negRatings, N):\n",
        "    user = posRating[0]\n",
        "    movie = posRating[1]\n",
        "    negRatings.append(movie)\n",
        "\n",
        "    user_input = np.full(len(negRatings), user)\n",
        "\n",
        "    predictions = model.predict([user_input, np.array(negRatings)], batch_size = 100)\n",
        "\n",
        "  # associate item with predictions\n",
        "    items = {}\n",
        "    for i in range(len(predictions)):\n",
        "        items[negRatings[i]] = predictions[i]\n",
        "    negRatings.pop()\n",
        "\n",
        "    rankedList = heapq.nlargest(N, items, items.get)\n",
        "    ndcg = evaluateNDCG(rankedList, movie)\n",
        "    hit = hitRate(rankedList, movie)\n",
        "\n",
        "    return hit, ndcg"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihO_JcoZtays",
        "outputId": "6701ebf5-bf20-4c4f-e98e-467ec567b908"
      },
      "source": [
        "NUM_EPOCHS = 20\n",
        "best_hr = 0\n",
        "best_ndcg = 0\n",
        "best_epoch = -1\n",
        "model_path = \"ResNet_Model.h5\"\n",
        "\n",
        "# Get examples for untrained model metrics.\n",
        "user_input, item_input, labels = get_train_instances(ratings, num_negatives = 4)\n",
        "\n",
        "# Get metrics for untrained model\n",
        "model.evaluate([np.array(user_input), np.array(item_input)],\n",
        "                      np.array(labels),\n",
        "                      batch_size = 16)\n",
        "\n",
        "hit_rate, ndcg = evaluate(model, test_ratings, test_negatives, N = 10)\n",
        "print('Initial Model', 'Hit Rate:', hit_rate, 'NDCG:', ndcg)\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Get training examples\n",
        "    user_input, item_input, labels = get_train_instances(ratings, num_negatives = 4)\n",
        "\n",
        "    # Train 1 epoch\n",
        "    hist = model.fit([np.array(user_input), np.array(item_input)],\n",
        "                      np.array(labels),\n",
        "                      batch_size = 16, epochs = 1)\n",
        "    \n",
        "    # Evaluate metrics\n",
        "    hit_rate, ndcg = evaluate(model, test_ratings, test_negatives, N = 10)\n",
        "    print('Epoch', epoch, 'Hit Rate:', hit_rate, 'NDCG:', ndcg)\n",
        "    model.save(model_path)\n",
        "\n",
        "    # Save best model\n",
        "    if hit_rate > best_hr:\n",
        "        best_hr, best_ncdg, best_iter = hit_rate, ndcg, epoch\n",
        "        model.save(model_path, overwrite=True)\n",
        "\n",
        "print(\"Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ncdg))\n",
        "print(\"The best Outer Product model is saved to %s\" %(model_path))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "295/295 [==============================] - 0s 1ms/step - loss: 0.6931\n",
            "Initial Model Hit Rate: 0.11134676564156946 NDCG: 0.05026819582143126\n",
            "295/295 [==============================] - 1s 1ms/step - loss: 0.5421\n",
            "Epoch 1 Hit Rate: 0.10922587486744433 NDCG: 0.0491398473648851\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.4794\n",
            "Epoch 2 Hit Rate: 0.11134676564156946 NDCG: 0.04935754014999356\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.3568\n",
            "Epoch 3 Hit Rate: 0.12513255567338283 NDCG: 0.057905456709228004\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.2377\n",
            "Epoch 4 Hit Rate: 0.1420996818663839 NDCG: 0.07000469104203644\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.1691\n",
            "Epoch 5 Hit Rate: 0.1474019088016967 NDCG: 0.07264460091797906\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.1235\n",
            "Epoch 6 Hit Rate: 0.15058324496288442 NDCG: 0.07191234692780876\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.1146\n",
            "Epoch 7 Hit Rate: 0.16224814422057265 NDCG: 0.07508707331118025\n",
            "295/295 [==============================] - 1s 2ms/step - loss: 0.1007\n",
            "Epoch 8 Hit Rate: 0.16224814422057265 NDCG: 0.0761648033801764\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.0951\n",
            "Epoch 9 Hit Rate: 0.17709437963944857 NDCG: 0.08401593698231274\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.0821\n",
            "Epoch 10 Hit Rate: 0.1728525980911983 NDCG: 0.0795644352244002\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.0867\n",
            "Epoch 11 Hit Rate: 0.176033934252386 NDCG: 0.08009140014702135\n",
            "295/295 [==============================] - 0s 1ms/step - loss: 0.0764\n",
            "Epoch 12 Hit Rate: 0.17179215270413573 NDCG: 0.07667335561285937\n",
            "295/295 [==============================] - 1s 2ms/step - loss: 0.0712\n",
            "Epoch 13 Hit Rate: 0.16436903499469777 NDCG: 0.07363337963271752\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.0657\n",
            "Epoch 14 Hit Rate: 0.1633085896076352 NDCG: 0.07390591683653423\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.0584\n",
            "Epoch 15 Hit Rate: 0.16755037115588547 NDCG: 0.07336474727822351\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.0673\n",
            "Epoch 16 Hit Rate: 0.16436903499469777 NDCG: 0.07282968402734316\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.0608\n",
            "Epoch 17 Hit Rate: 0.1633085896076352 NDCG: 0.07440021048316132\n",
            "295/295 [==============================] - 1s 2ms/step - loss: 0.0577\n",
            "Epoch 18 Hit Rate: 0.17073170731707318 NDCG: 0.07815094120256982\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.0538\n",
            "Epoch 19 Hit Rate: 0.1664899257688229 NDCG: 0.07725358807358007\n",
            "295/295 [==============================] - 0s 2ms/step - loss: 0.0562\n",
            "Epoch 20 Hit Rate: 0.1728525980911983 NDCG: 0.08005841026698018\n",
            "Best Iteration 9:  HR = 0.1771, NDCG = 0.0840. \n",
            "The best Outer Product model is saved to ResNet_Model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_guNrdahaT8"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLbfkjViVKdn",
        "outputId": "2b13bf4d-b835-41a3-b9bd-69540934e5e5"
      },
      "source": [
        "# Set desired user and item values from the dataset above\n",
        "user = [1]\n",
        "item = [1]\n",
        "\n",
        "# Make prediction\n",
        "result = model.predict([np.array(user), np.array(item)])\n",
        "print('Predicted probability for user', user, 'interacting with item', item, result[0][0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted probability for user [1] interacting with item [1] 0.4999733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clZ3RF5bhwlS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}